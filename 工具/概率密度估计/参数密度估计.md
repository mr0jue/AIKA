#参数密度估计 （Parametric Density Estimation）是根据先验知识假设随机变量服从某种分布，然后通过训练样本来估计分布的参数。假设数据服从某个已知概率密度函数形式的分布，然后根据训练样本去估计概率密度函数的参数。

令 $\mathcal{D}=\left\{\mathbf{x}^{(n)}\right\}_{i=1}^{N}$ 为从某个末知分布中独立抽取的N训练样本, 假设这些样本服从一个概率分布函数 ${p(\mathbf{x} | \theta)}$, 其对数似然函数为 $${ \log p(\mathcal{D} | \theta)=\sum_{n=1}^{N} \log p\left(\mathbf{x}^{(n)} | \theta\right) . }$$ 我们要估计一个参数 ${\theta^{M L}}$ 来使得 $$\theta^{M L}=\underset{\theta}{\arg \max } \sum_{n=1}^{N} \log p\left(\mathbf{x}^{(n)} \mid \theta\right).$$这样参数估计问题就转化为 #最优化问题 。
参见[[常见分布的密度估计]]

在实际应用中，参数密度估计一般存在以下问题：
1）模型选择问题：即如何选择数据分布的密度函数。实际数据的分布往往是非常复杂的，而不是简单的正态分布或多项分布。
2）不可观测变量问题：即我们用来训练的样本只包含部分的可观测变量，还有一些非常关键的变量是无法观测的，这导致我们很难准确估计数据的真实分布。包含不可观测变量的密度估计问题一般需要使用 EM 算法。
3）维度灾难问题：即高维数据的参数估计十分困难。随着维度的增加，估计参数所需要的样本数量指数增加。在样本不足时会出现过拟合。