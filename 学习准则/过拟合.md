过拟合： 给定一个假设空间$F$，一个假设$f$ 属于$F$，如果存在其他的假设 $f′$ 也属于 $F$, 使得在训练集上 $f$ 的损失比 $f′$ 小，但在整个样本空间上$f′$ 比$f$ 的损失小，那么就说假设$f$过度拟合训练数据[Mitchell, 1997]。

根据大数定理可知，当训练集大小$|D|$趋向于无穷大时， #经验风险 就趋向于 #期望风险 。然而通常情况下，我们无法获取无限的训练样本，并且训练样本往往是真实数据的一个很小的子集或者包含一定的噪声数据，不能很好地反映全部数据的真实分布。 #经验风险最小化 准则很容易导致模型在训练集上错误率很低，但是在未知数据上错误率很高。这就是所谓的 #过拟合 （ #Overfifitting ）。

和过拟合相反的一个概念是 #欠拟合 （underfifitting），即模型不能很好地拟合训练数据，在训练集的错误率比较高。欠拟合一般是由于模型能力不足造成的。 

图给出了欠拟合和过拟合的示例。
![[欠拟合和过拟合示例.png]]
