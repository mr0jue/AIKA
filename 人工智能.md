# 概述
简单地讲，人工智能（Artificial Intelligence，AI）就是让机器具有人类的 #智能 ，这也是人们长期追求的目标．人工智能是计算机科学的一个分支，主要研究、开发用于模拟、延伸和扩展人类智能的理论、方法、技术及应用系统等． #图灵测试 是促使人工智能从哲学探讨到科学研究的一个重要因素，引导了人工智能的很多研究方向．因为要使得计算机能通过图灵测试，计算机就必须具备理解语言、学习、记忆、推理、决策等能力．这样，人工智能就延伸出了很多不同的子学科，比如机器感知、学习、语言、记忆、决策等．所有这些研究领域都可以看成是人工智能的研究范畴．

目前，人工智能的主要领域大体上可以分为以下几个方面：
1） 感知：模拟人的感知能力，对外部刺激信息（视觉和语音等）进行感知和加工．主要研究领域包括 #语音信息处理 和 #计算机视觉 等．
2） 学习：模拟人的学习能力，主要研究如何从样例或从与环境的交互中进行学习．主要研究领域包括 #监督学习 、 #无监督学习 和 #强化学习 等．
3） 认知：模拟人的认知能力，主要研究领域包括 #知识表示 、 #自然语言理解 、推理、规划、决策等．

[[人工智能发展历史|人工智能从诞生至今]]，经历了一次又一次的繁荣与低谷，其发展历程大体上可以分为“推理期”“知识期”和“学习期”[周志华, 2016]．
尽管[[人工智能的流派]]非常多，但主流的方法大体上可以归结为 #符号主义 （Symbolism）和 #连接主义 （Connectionism）。
在人工智能领域，[[机器学习]]（Machine Learning，ML）从一开始就是一个重要的研究方向．但直到1980年后，机器学习因其在很多领域的出色表现，才逐渐成为热门学科．
[[深度学习]]（Deep Learning）是近年来发展十分迅速的研究领域，并且在人工智能的很多子领域都取得了巨大的成功．从根源来讲，深度学习是机器学习的一个分支，是指一类问题以及解决这类问题的方法．


*人工智能 这里关于什么是“智能”并没有一个很明确的定义，但一般认为智能（或特指人类智能）是知识和智力的总和，都和大脑的思维活动有关．人类大脑是经过了上亿年的进化才形成了如此复杂的结构，但我们至今仍然没有完全了解其工作机理．虽然随着神经科学、认知心理学等学科的发展，人们对大脑的结构有了一定程度的了解，但对大脑的智能究竟是怎么产生的还知道得很少．我们并不理解大脑的运作原理，以及如何产生意识、情感、记忆等功能．因此，通过“复制”人脑来实现人工智能在目前阶段是不切实际的．在发展了 60 多年后，人工智能虽然可以在某些方面超越人类，但想让机器真正通过 #图灵测试 ，具备真正意义上的人类智能，这个目标看上去仍然遥遥无期．*

# 其他

### 人工智能学科诞生的标志性事件
和很多其他学科不同， #人工智能 这个学科的诞生有着明确的标志性事件，就是 1956 年的 达特茅斯（Dartmouth）会议．在这次会议上，“人工智能”被提出并作为本研究领域的名称．同时，人工智能研究的使命也得以确定．John McCarthy提出了人工智能的定义：人工智能就是要让机器的行为看起来就像是人所表现出的智能行为一样．

---
### 归纳偏置
在机器学习中，很多学习算法经常会对学习的问题做一些假设，这些假设就称为 #归纳偏置 （Inductive Bias）[Mitchell, 1997]．比如在最近邻分类器中，我们会假设在特征空间中，一个小的局部区域中的大部分样本同属一类．在朴素贝叶斯分类器中，我们会假设每个特征的条件概率是互相独立的．
归纳偏置在 #贝叶斯学习 中也经常称为 #先验 （Prior）

---
### 贡献度分配问题
#贡献度分配问题 即一个系统中不同的组件（component）对 最 终系统输出结果的贡献或影响．


---
### 完备性
如果p个基向量刚好可以支撑p维的欧氏空间，则这p个基向量是 #完备 的 。如果p个基向量可以支撑d维的欧氏空间，并且p > d，则这p个基向量是 #过完备 的，冗余的。
“ 过完备”基向量一般是指的是基向量个数远远大于其支撑空间维度。因此这些基向量一般是不具备独立、正交等性质。

---
### 稀疏性
对于一个向量, 其 #稀疏性 定义为非零元素的比例。如果一个向量只有很少的几个非零元素, 就说这个向量是稀疏的。严格的稀疏向量有时比较难以得到，因此如果一个向量只有少数几个远大于零的元素，其它元素都接近于0，我们也称这个向量为稀疏向量。

---
### 稀疏性衡量函数
对于一个向量 ${\mathbf{z} \in \mathbb{R}^{p}}$, #稀疏性衡量函数  ${\rho(\mathbf{z})}$ 是给向量 ${\mathbf{z}}$ 一个标量分数。 ${\mathbf{z}}$ 越稀疏, ${\rho(\mathbf{z})}$ 越小。 
稀疏性衡量函数有多种选择, 最直接的衡量向量 ${\mathrm{z}}$ 稀疏性的函数是
	${\ell_{0}}$ 范式       ${ \left.\rho(\mathbf{z})=\sum_{i=1}^{p} \mathbf{I}\left(\left|z_{i}\right|>0\right)\right) }$ 
但 ${\ell_{0}}$ 范数不满足连续可导, 因此很难进行优化。在实际中, 稀疏性衡量函数通常使用
	${\ell_{1}}$ 范数       ${ \rho(\mathbf{z})=\sum_{i=1}^{p}\left|z_{i}\right| }$ 
	对数函数    ${ \rho(\mathbf{z})=\sum_{i=1}^{p} \log \left(1+z_{i}^{2}\right) }$ 
	指数函数    ${ \rho(\mathbf{z})=\sum_{i=1}^{p}-\exp \left(-z_{i}^{2}\right) }$ 


---
### 饱和
#饱和 ：对于函数 ${f(x)}$, 若 ${x \rightarrow-\infty}$ 时, 其导数 ${f{\prime}(x) \rightarrow 0}$, 则称其为左饱和。若 ${x \rightarrow+\infty}$ 时, 其导数 ${f{\prime}(x) \rightarrow 0}$, 则称其为右饱和。当同时满足 左、右饱和时, 就称为两端饱和。

---
### 连续属性、离散属性、有序属性、无序属性
我们常将属性划分为“ #连续属性”（continuous attribute)和“ #离散属性”（categorical attribute),前者在定义域上有无穷多个可能的取值，后者在定义域上是有限个取值. “连续属性” 亦称“数值属性” (numerical attribute), “离散属性” 亦称 “列名属性” (nominal attribute).

例如定义域为{1,2,3}的离散属性与连续属性的性质更接近一些,能直接在属性值上计算距离：“1”与“2”比较接近、与“3”比较远，这样的属性称为“ #有序属性”(ordinalattribute);而定义域为{飞机，火车，轮船}这样的离散属性则不能直接在属性值上计算距离，称为“ #无序属性”（non-ordinalattribute)

---
### 维度灾难
#维度灾难 （Curse of Dimensionality）

---
### 过度参数
#过度参数 (Over-Parameterization）是指模型参数的数量远远大于训练数据的数量。

---
### 常见的向量
#全0向量 ：指所有元素都为0的向量，用0表示。全0向量为笛卡尔坐标系中的原点。
#全1向量 ：指所有值为1的向量，用1表示。
#one-hot 向量 为有且只有一个元素为1，其余元素都为0的向量。one-hot向量是在数字电路中的一种状态编码，指对任意给定的状态，状态寄存器中只有l位为1，其余位都为0。

---
### 局部表示、分布式表示 和 嵌入
 以颜色表示为例，我们一般有两种表示方法。
我们有很多词来形容颜色的词，除了基本的“红”、“蓝”、“绿”、“白”、“黑”等之外，有很多以地区或物品命名的，比如“中国红”、“天蓝色”、“咖啡色”、“琥珀色”等等。一种表示颜色的方式是以不同名字来命名不同的颜色，这种表示方式叫做 #局部表示 ，也称为离散表示或符号表示。局部表示通常可以表示为 #one-hot 向量的形式。假设所有颜色的名字构成一个词表V，词表大小为|V|。我们可以用一个|V| 维的one-hot 向量来表示每一种颜色。第i种颜色的one-hot 向量中，第i维的值为1，其它都为0。
局部表示有两个不足之处：
1）one-hot向量的维数很高，且不能扩展。如果有一种新的颜色，我们就需要增加一维来表示；
2）不同颜色之间的相似度都为0，即我们无法知道“红色”和“中国红”的相似度要比“红色”和“黑色”的相似度要高。
另一种表示颜色的方式是用RGB值来表示颜色，不同颜色对应到R、G、B三维空间中一个点，这种表示方式叫做分布式表示。分布式表示通常可以表示为低维的稠密向量。
相比与局部表示，分布式表示的表示能力要比局部表示强很多，分布式表示的向量维度一般都比较低。我们只需要用一个三维的稠密向量就可以表示所有颜色。并且分布式表示也很容易表示新的颜色名。此外，不同颜色之间的相似度也很容易计算。
我们可以使用神经网络来将高维的局部表示空间 ${\mathbb{R}^{|\mathcal{V}|}}$ 映射到一个非常低维的分布式表示空间 ${\mathbb{R}^{d}, d \ll|\mathcal{V}|}$ 。在这个低维空间中, 每个特征不在是坐标轴上的点，而是分散在整个低维空间中。在机器学习中，这个过程也称为 #嵌入 （ #embedding ）。嵌入通常指将一个度量空间中的一些对象映射到另一个低维的度量空间中，并尽可能保持不同对象之间的拓扑关系。比如自然语言中词的分布式表示，也经常叫做词嵌入。
图展示了一个3维one-hot向量空间和一个2维嵌入空间的对比。在one-hot向量空间中，每个特征都位于坐标轴上，每个坐标轴上一个特征。而在低维的嵌入空间中，每个特征都不在坐标轴上，特征之间可以计算相似度。
![[One-hot向量空间与嵌入空间.png|300]]


---
### 动力系统
#动力系统 （Dynamical System）是一个数学上的概念，指系统状态按照一定的规律随时间变化的系统。具体地讲，动力系统是使用一个函数来描述一个给定空间（如某个物理系统的状态空间）中所有点随时间的变化情况。

---
### 通用近似定理
#通用近似定理 (Universal Approximation Theorem)  [Cybenko, 1989, Hornik et al., 1989]: 
令  $\varphi(\cdot)$  是一个非常数、有界、单调递增的连续函数,  $\mathcal{I}_{d}$  是一个  $d$  维的单位超立方体  $[0,1]^{d}$ ,  $C\left(\mathcal{I}_{d}\right)$  是定义在 $\mathcal{I}_{d}$  上的连续函数集合。对于任何一个函数  $f \in   C\left(\mathcal{I}_{d}\right)$ , 存在一个整数  m , 和一组实数  $v_{i}, b_{i} \in \mathbb{R}$  以及实数向量  $\mathbf{w}_{i} \in \mathbb{R}^{d}, i=1, \cdots, m$, 以至于我们可以定义函数$$F(\mathbf{x})=\sum_{i=1}^{m} v_{i} \varphi\left(\mathbf{w}_{i}^{\mathrm{T}} \mathbf{x}+b_{i}\right)$$作为函数  $f$  的近似实现, 即$$|F(\mathbf{x})-f(\mathbf{x})|<\epsilon, \forall \mathbf{x} \in \mathcal{I}_{d}$$
其中 $\epsilon>0$  是一个很小的正数。
通用近似定理在实数空间 $\mathbb{R}^{d}$ 中的有界闭集上依然成立。

---
### Borel可测函数
定义在实数空间 $\mathbb{R}^{d}$ 中的有界闭集上的任意连续函数，也称为 #Borel可测函数 。

---

---
### Frobenius范数
#Frobenius范数： $${ \|W\|_{F}^{2}=\sum_{l=1}^{L} \sum_{i=1}^{m^{(l)}} \sum_{j=1}^{m^{(l-1)}}\left(W_{i j}^{(l)}\right)^{2} . }$$

---
### 人工智能低谷
#人工智能低谷 也叫人工智能冬天（AI Winter），指人工智能史上研究资金及学术界研究兴趣都大幅减少的时期．人工智能领域经历过好几次低谷期．每次狂热高潮之后，紧接着是失望、批评以及研究资金断绝，然后在几十年后又重燃研究兴趣．1974～1980 年及1987～1993年是两个主要的低谷时期，其他还有几个较小的低谷.

---
### 学习
对于某类任务 T 和性能度量 P ，一个计算机程序被认为可以从经验 E 中 #学习 ，是指计算机程序通过经验 E 改进后，在任务 T 上由性能度量 P 衡量的性能有所提升。

---
### 智能
#智能 （Intelligence）是现代生活中很常见的一个词，比如智能手机、智能家居、智能驾驶等。在不同使用场合中，智能的含义也不太一样。比如“智能手机”中 的“智能”一般是指由计算机控制并具有某种智能行为。这里的“计算机控制”+ “智能行为”隐含了对人工智能的简单定义。“智能”可以理解为“智力”和“能力”。前者是智能的基础，后者是指获取和运用知识求解的能力。


---
### 图灵机
#图灵机 （Turing Machine）是图灵在1936年提出的一种抽象数学模型，可以用来模拟任何可计算问题[Turing, 1937]。图灵机有以下几个组件构成：
1. 一条无限长的纸带：纸带上有一个个方格组成，每个方格可以存储一个符号；
2. 一个符号表：纸带上可能出现的所有符号的集合，包含一个特殊的空白符。
3. 一个读写头：指向纸带上某个方格的指针，每次可以向左或右移动一个位置，并可以读取、擦除、写入当前方格中的内容；
4. 一个状态寄存器：用来保存图灵机当前所处的状态，其中包含两个特殊的状态：起始状态和终止状态；
5. 一套控制规则：根据当前机器所处的状态以及当前读写头所指的方格上的符号来确定读写头下一步的动作，令机器进入一个新的状态。

图灵机的结构如图所示，其中控制器包括状态寄存器、控制规则。
![[图灵机结构示例.png|300]]

---
### 图灵测试
1950 年，阿兰·图灵（Alan Turing）发表了一篇有着重要影响力的论文《Computing Machinery and Intelligence》，讨论了创造一种“智能机器”的可能性．由于“ #智能 ”一词比较难以定义，他提出了著名的 #图灵测试 ：“一个人在不接触对方的情况下，通过一种特殊的方式和对方进行一系列的问答．如果在相当长时间内，他无法根据这些问题判断对方是人还是计算机，那么就可以认为这个计算机是智能的”．图灵测试是促使人工智能从哲学探讨到科学研究的一个重要因素，引导了人工智能的很多研究方向．

---
### 图灵完备
#图灵完备 （Turing Completeness）是指一种数据操作规则，比如一种计算机编程语言，可以实现 #图灵机 （Turing Machine）的所有功能，解决所有的可计算问题。目前主流的编程语言（比如C++，Java，Python等）都是图灵完备的。

---
### 语义鸿沟
#语义鸿沟 （Semantic Gap）问题是指输入数据的底层特征和高层语义信息之间的不一致性和差异性。比如给定一些关于“车”的图片，由于图片中每辆车的颜色和形状等属性都不尽相同，不同图片在像素级别上的表示（即底层特征）差异性也会非常大。但是我们人理解这些图片是建立在比较抽象的高层语义概念上的。

---
### 感受野 
 #感受野 （Receptive Field）主要是指听觉、视觉等神经系统中一些神经元的特性，即神经元只接受其所支配的刺激区域内的信号。在视觉神经系统中，视觉皮层中的神经细胞的输出依赖于视网膜上的光感受器。视网膜上的光感受器受刺激兴奋时，将神经冲动信号传到视觉皮层，但不是所有视觉皮层中的神经元都会接受这些信号。一个神经元的感受野是指视网膜上的特定区域，只有这个区域内的刺激才能够激活该神经元。
 
---
### 尺度不变特征变换
#尺度不变特征变换 （Scale Invariant Feature Transform， #SIFT ）

---
### 带通性
#带通性 是指不同尺度下空间结构的敏感性．比如， #带通滤波器 （Bandpass Filter）是指容许某个频率范围的信号通过，同时屏蔽其他频段的设备．