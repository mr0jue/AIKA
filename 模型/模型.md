对于一个 #机器学习 任务, 首先要确定其输入空间 ${\mathcal{X}}$ 和输出空间 ${y}$. 不同机器学习任务的主要区别在于输出空间不同,而输入空间默认为样本的特征空间. 
在二分类问题中 ${y=\{+1,-1\}}$, 在 ${C}$ 分 类问题中 ${y=\{1,2, \cdots, C\}}$, 而在回归问题中 ${y=\mathbb{R}}$. 

输入空间 ${X}$ 和输出空间 ${y}$ 构成了一个样本空间. 对于样本空间中的样本 ${(\boldsymbol{x}, y) \in x \times y}$, 假定 ${\boldsymbol{x}}$ 和 ${y}$ 之间的关系可以通过一个末知的 #真实映射函数 ${y=g(\boldsymbol{x})}$ 或 #真实条件概率分布 ${p_{r}(y | \boldsymbol{x})}$ 来描述. 机器学习的目标是找到一个模型来近似真实映射函数 ${g(x)}$ 或真实条件概率分布 ${p_{r}(y | x)}$. 
由于我们不知道真实的映射函数 ${g(x)}$ 或条件概率分布 ${p_{r}(y | x)}$ 的具体形式, 因而只能根据经验来假设一个函数集合 ${\mathcal{F}}$, 称为 #假设空间 ( Hypothesis Space ), 然后通过观测其在训练集 ${\mathcal{D}}$ 上的特性, 从中选择一个理想的 #假设 (Hypothesis ) ${f^{*} \in \mathcal{F}}$. 
假设空间 ${\mathcal{F}}$ 通常为一个参数化的函数族 ${ \mathcal{F}=\left\{f(\boldsymbol{x} ; \theta) | \theta \in \mathbb{R}^{D}\right\}, }$ 其中 ${f(\boldsymbol{x} ; \theta)}$ 是参数为 ${\theta}$ 的函数, 也称为 #模型 (Model), ${D}$ 为参数的数量. 
常见的假设空间可以分为线性和非线性两种, 对应的模型 ${f}$ 也分别称为[[线性模型]]和[[非线性模型]]. 