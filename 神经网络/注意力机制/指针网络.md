# 指针网络
注意力机制主要是用来做信息笑选, 从输入信息中选取相关的信息。注意力机制可以分为两步：一是计算注意力分布 $\alpha$, 二是根据 $\alpha$ 来计算输入信息的加权平均。我们可以只利用注意力机制中的第一步, 将注意力分布作为一个软性的指针 (pointer) 来指出相关信息的位置。
指针网络 (Pointer Network) [Vinyals et al., 2015] 是一种序列到序列模型, 输入是长度为 $n$ 的向量序列 $X=\mathbf{x}_{1}, \cdots, \mathbf{x}_{n}$, 输出是下标序列 $c_{1: m}=c_{1}, c_{2}, \cdots, c_{m}$, $c_{i} \in[1, n], \forall i$ 。
和一般的序列到序列任务不同, 这里的输出序列是输入序列的下标 (索引)。 比如输入一组乱序的数字, 输出为按大小排序的输入数字序列的下标。比如输 入为 $20,5,10$, 输出为 $1,3,2$ 。
条件概率 $p\left(c_{1: m} \mid \mathbf{x}_{1: n}\right)$ 可以写为
$$
\begin{aligned}
p\left(c_{1: m} \mid \mathbf{x}_{1: n}\right) &=\prod_{i=1}^{m} p\left(c_{i} \mid c_{1: i-1}, \mathbf{x}_{1: n}\right) \\
& \approx \prod_{i=1}^{m} p\left(c_{i} \mid \mathbf{x}_{c_{1}}, \cdots, \mathbf{x}_{c_{i-1}}, \mathbf{x}_{1: n}\right)
\end{aligned}
$$
其中条件概率 $p\left(c_{i} \mid \mathbf{x}_{c_{1}}, \cdots, \mathbf{x}_{c_{i-1}}, \mathbf{x}_{1: n}\right)$ 可以通过注意力分布来计算。假设用一个循环神经网络对 $\mathbf{x}_{c_{1}}, \cdots, \mathbf{x}_{c_{i-1}}, \mathbf{x}_{1: n}$ 进行编码得到向量 $\mathbf{h}_{i}$, 则
$$
p\left(c_{i} \mid c_{1: i-1}, \mathbf{x}_{1: n}\right)=\operatorname{softmax}\left(s_{i, j}\right)
$$
其中 $s_{i, j}$ 为在解码过程的第 $i$ 步时, 每个输入向量的末归一化的注意力分布,
$$
s_{i, j}=\mathbf{v}^{\mathrm{T}} \tanh \left(W \mathbf{x}_{j}+U \mathbf{h}_{i}\right), \forall j \in[1, n]
$$
其中 $\mathbf{v}, W, U$ 为可学习的参数。
![[指针网络.png|500]]