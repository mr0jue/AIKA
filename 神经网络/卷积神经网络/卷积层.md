#卷积层 的作用是提取一个局部区域的特征，不同的 #卷积核 相当于不同的特征提取器。既然卷积网络主要应用在图像处理上，而图像为两维结构，因此为了更充分地利用图像的局部信息，通常将神经元组织为三维结构的神经层，其大小为高度M×宽度N×深度D，有D 个M × N 大小的特征映射构成。

#特征映射 （Feature Map）为一幅图像（或其它特征映射）在经过卷积提取到的特征，每个特征映射可以作为一类抽取的图像特征。为了提高卷积网络的表示能力，可以在每一层使用多个不同的特征映射，以更好地表示图像的特征。

在输入层，特征映射就是图像本身。如果是灰度图像，就是有一个特征映射，深度D = 1；如果是彩色图像，分别有RGB三个颜色通道的特征映射，输入层深度D = 3。

不失一般性，假设一个卷积层的结构如下
- 输入特征映射组: ${\mathbf{X} \in \mathbb{R}^{M \times N \times D}}$ 为三维 #张量 ( #tensor), 其中每个 #切片 ( #slice) 矩阵 ${X^{d} \in \mathbb{R}^{M \times N}}$ 为一个输入特征映射, ${1 \leq d \leq D}$;
- 输出特征映射组: ${\mathbf{Y} \in \mathbb{R}^{M{\prime} \times N{\prime} \times P}}$ 为三维张量, 其中每个切片矩阵 ${Y^{p} \in}$ ${\mathbb{R}^{M{\prime} \times N{\prime}}}$ 为一个输出特征映射, ${1 \leq p \leq P}$; 
- #卷积核: ${\mathbf{W} \in \mathbb{R}^{m \times n \times D \times P}}$ 为四维张量, 其中每个切片矩阵 ${W^{p, d} \in \mathbb{R}^{m \times n}}$ 为一个两维卷积核, ${1 \leq d \leq D, 1 \leq p \leq P}$ 。 

图给出卷积层的三维结构表示。![[卷积层的三维结构表示.png|600]]
为了计算输出特征映射 ${Y^{p}}$, 用卷积核 ${W^{p, 1}, W^{p, 2}, \cdots, W^{p, D}}$ 分别对输入特征映射 ${X^{1}, X^{2}, \cdots, X^{D}}$ 进行卷积, 然后将卷积结果相加, 并加上一个标量偏置 ${b}$ 得到卷积层的净输入 ${Z^{p}}$, 再经过非线性激活函数后得到输出特征映射 ${Y^{p}}$ 。 $${ \begin{array}{l}
Z^{p} =\mathbf{W}^{p} \otimes \mathbf{X}+b^{p}=\sum_{d=1}^{D} W^{p, d} \otimes X^{d}+b^{p}, \\ 
Y^{p} =f\left(Z^{p}\right) . 
\end{array}}$$ 其中 ${\mathbf{W}^{p} \in \mathbb{R}^{m \times n \times D}}$ 为三维卷积核, ${f(\cdot)}$ 为非线性激活函数, 一般用 #ReLU 函数。如果希望卷积层输出 ${P}$ 个特征映射, 可以将上 述计算机过程重复 ${P}$ 次, 得到 ${P}$ 个输出特征映射 ${Y^{1}, Y^{2}, \cdots, Y^{P}}$ 。 
在输入为 ${\mathbf{X} \in \mathbb{R}^{M \times N \times D}}$, 输出为 ${\mathbf{Y} \in \mathbb{R}^{M{\prime} \times N{\prime} \times P}}$ 的卷积层中, 每一个输入特征映射都需要 ${D}$ 个滤波器以及一个偏置。假设每个滤波器的大小为 ${m \times n}$, 那么共需要 ${P \times D \times(m \times n)+P}$ 个参数。

图给出计算示例。
![[卷积层中从输入特征映射组X到输出特征映射Y的计算示例.png|600]]

