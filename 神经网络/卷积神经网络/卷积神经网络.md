#卷积神经网络 （Convolutional Neural Network， #CNN 或ConvNet）是受生物学上 #感受野 的机制而提出，最早是主要用来处理图像信息。[[卷积]] ，也叫摺积，是分析数学中一种重要的运算。在信号处理或图像处理中，经常使用一维或二维卷积。
如果用全连接前馈网络来处理图像时，会存在以下两个问题：
1）参数太多：如果输入图像大小为100 × 100 × 3（即图像高度为100，宽度为100，3个颜色通道：RGB）。在全连接前馈网络中，第一个隐藏层的每个神经元到输入层都有100 × 100 × 3 = 30000 个相互独立的连接，每个连接都对应一个权重参数。随着隐藏层神经元数量的增多，参数的规模也会急剧增加。这会导致整个神经网络的训练效率会非常低，也很容易出现过拟合。
2）局部不变性特征：自然图像中的物体都具有局部不变性特征，比如在尺度缩放、平移、旋转等操作不影响其语义信息。而全连接前馈网络很难提取这些局部不变特征，一般需要进行数据增强来提高性能。

目前的卷积神经网络一般是由 [[卷积层]]、[[汇聚层]] 和全连接层交叉堆叠而成的 #前馈神经网络 ，使用 #反向传播算法 进行训练。
图给出典型的卷积网络结构。全连接层一般在卷积网络的最顶层。
![[典型的卷积网络结构.png]]

一个卷积块为连续 M 个卷积层和b个汇聚层（ M 通常设置为2 ∼ 5，b为0或1）。一个卷积网络中可以堆叠N 个连续的卷积块，然后在接着 K 个全连接层（N 的取值区间比较大，比如1 ∼ 100或者更大；K一般为0 ∼ 2）。

卷积神经网络有三个结构上的特性： #局部连接 ， #权重共享 以及 #汇聚 。这些特性使得卷积神经网络具有一定程度上的平移、缩放和旋转不变性。和前馈神经网络相比，卷积神经网络的参数更少。

在卷积的标准定义基础上，还可以引入 卷积核的 #滑动步长 和 #零填充 和一些 [[卷积的变种]] 来增加卷积的多样性，可以更灵活地进行特征抽取。

目前，整个网络结构趋向于使用更小的卷积核（比如1 × 1和3 × 3）以及更深的结构（比如层数大于50）。此外，由于卷积的操作性越来越灵活（比如不同的步长），汇聚层的作用变得也越来越小，因此目前比较流行的卷积网络中，汇聚层的比例也逐渐降低，趋向于全卷积网络。


卷积神经网络主要使用在图像和视频分析的各种任务上，比如 #图像分类 、 #人脸识别 、 #物体识别 、 #图像分割 等，其准确率一般也远远超出了其它的神经网络模型。近年来卷积神经网络也广泛地应用到 #自然语言处理 、 #推荐系统 等领域。
