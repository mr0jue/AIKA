#卷积 （ #Convolution ），也叫摺积，是分析数学中一种重要的运算。在信号处理或图像处理中，经常使用一维或二维卷积。这里我们只考虑离散序列的情况。

在卷积的标准定义基础上，还可以引入滤波器的滑动步长和零填充来增加卷积的多样性，可以更灵活地进行特征抽取。

## 一维卷积
一维卷积经常用在信号处理中, 用于计算信号的延迟累积。假设一个信号发生器每个时刻 ${t}$ 产生一个信号 ${x_{t}}$, 其信息的衰减率为 ${w_{k}}$, 即在 ${k-1}$ 个时间步长后, 信息为原来的 ${w_{k}}$ 倍。假设 ${w_{1}=1, w_{2}=1 / 2, w_{3}=1 / 4}$, 那么在时刻 ${t}$ 收到的信号 ${y_{t}}$ 为当前时刻产生的信息和以前时刻延迟信息的叠加, $${\begin{align}{l} y_{t} &=1 \times x_{t}+1 / 2 \times x_{t-1}+1 / 4 \times x_{t-2} \\ &=w_{1} \times x_{t}+w_{2} \times x_{t-1}+w_{3} \times x_{t-2} \\ &=\sum_{k=1}^{3} w_{k} \cdot x_{t-k+1} \end{align}}$$ 我们把 ${w_{1}, w_{2}, \cdots}$ 称为 #滤波器 （ #Filter ）或 #卷积核 （Convolution Kernel）。 假设滤波器长度为 ${m}$, 它和一个信号序列 ${x_{1}, x_{2}, \cdots}$ 的卷积为 $${ y_{t}=\sum_{k=1}^{m} w_{k} \cdot x_{t-k+1} }$$ 信号序列 ${\mathrm{x}}$ 和滤波器 ${\mathrm{w}}$ 的卷积定义为 $${ \mathbf{y}=\mathbf{w} \otimes \mathrm{x}, }$$ 其中 ${\otimes}$ 表示卷积运算。 一般情况下滤波器的长度 ${m}$ 远小于信号序列长度 ${n}$ 。当滤波器 ${f_{k}=1 / m, 1 \leq}$ ${k \leq m}$ 时, 卷积相当于信号序列的 #移动平均

图给出了一维卷积示例。滤波器为 ${[-1,0,1]}$, 连接边上的数字为滤波器中的权重。
![[一维卷积示例.png|300]]

## 二维卷积
卷积也经常用在图像处理中。因为图像为一个两维结构, 所以需要将一维卷积进行扩展。给定一个图像 ${X \in \mathbb{R}^{M \times N}}$, 和滤波器 ${W \in \mathbb{R}^{m \times n}}$, 一般 ${m<<M, n<<N}$, 其卷积为 $${ y_{i j}=\sum_{u=1}^{m} \sum_{v=1}^{n} w_{u v} \cdot x_{i-u+1, j-v+1} . }$$
图给出了二维卷积示例。
![[二维卷积示例.png|600]]


常用的 #均值滤波 （mean filter）就是当前位置的像素值设为滤波器窗口中所有像素的平均值, 也就是 ${f_{u v}=\frac{1}{m n}}$ 。
在图像处理中，卷积经常作为 #特征提取 的有效方法。一幅图像在经过卷积操作后得到结果称为 #特征映射 （Feature Map）。图给出在图像处理中几种常用的滤波器，以及其对应的特征映射。图中最上面的滤波器是常用的 #高斯滤波器 ，可以用来对图像进行平滑去噪；中间和最下面的过滤器可以用来提取边缘特征。

![[图像处理中几种常用的滤波器示例.png|600]]



## 互相关
在机器学习和图像处理领域，卷积的主要功能是在一个图像（或某种特征）上滑动一个卷积核（即滤波器），通过卷积操作得到一组新的特征。在计算卷积的过程中，需要进行卷积核翻转。（翻转就是从两个维度（从上到下、从左到右）颠倒次序，即旋转180度。）在具体实现上，一般会以互相关操作来代替卷积，从而会减少一些不必要的操作或开销。 #互相关 （Cross-Correlation）是一个衡量两个序列相关性的函数，通常是用滑动窗口的点积计算来实现。给定一个图像 ${X \in \mathbb{R}^{M \times N}}$ 和卷积核 ${W \in \mathbb{R}^{m \times n}}$, 它们的互相关为 $${ y_{i j}=\sum_{u=1}^{m} \sum_{v=1}^{n} w_{u v} \cdot x_{i+u-1, j+v-1} . }$$和卷积公式对比可知，互相关和卷积的区别在于卷积核仅仅是否进行翻转。因此互相关也可以称为不翻转卷积。互相关和卷积的区别也可以理解为图像是否进行翻转。
在神经网络中使用卷积是为了进行特征抽取，卷积核是否进行翻转和其特征抽取的能力无关。特别是当卷积核是可学习的参数时，卷积和互相关是等价的。因此，为了实现上（或描述上）的方便起见，我们用互相关来代替卷积。事实上，很多深度学习工具中卷积操作其实都是互相关操作。





