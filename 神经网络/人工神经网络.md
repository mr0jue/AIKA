#人工神经网络 （Artifificial Neural Network，ANN ）是指一系列受生物学和神经学启发的数学模型。这些模型主要是通过对 #人类大脑 的 #生物神经元 网络进行抽象，构建 #人工神经元  （早期尝试例如 #MP神经元 ），并按照一定拓扑结构来建立人工神经元之间的连接，来模拟生物神经网络。在人工智能领域，人工神经网络也常常简称为 #神经网络 （Neural Network，NN）或神经模型（Neural Model）。

人工神经网络是一种模拟人脑神经网络而设计的数据模型或计算模型，它从结构、实现机理和功能上模拟人脑神经网络。人工神经网络与生物神经元类似，由多个节点（[[人工神经元]]）相互连接而成，可以用来对数据之间的复杂关系进行建模。不同节点之间的连接被赋予了不同的权重，每个权重代表了一个节点对另一个节点的影响大小。每个节点代表一种特定函数，来自其他节点的信息经过其相应的权重综合计算，输入到一个激励函数中并得到一个新的活性值（兴奋或抑制）。

从系统观点看，人工神经元网络是由大量神经元通过极其丰富和完善的连接而构成的自适应非线性动态系统。

神经网络最早是作为一种主要的 #连接主义 模型。20 世纪 80 年代后期，最流行的一种连接主义模型是分布式并行处理（Parallel Distributed Processing，PDP）网络[Rumelhart et al., 1986]，其有3个主要特性：
1）信息表示是分布式的（非局部的）；
2）记忆和知识是存储在单元之间的连接上；
3）通过逐渐改变单元之间的连接强度来学习新的知识。

连接主义的神经网络有着多种多样的网络结构以及学习方法，虽然早期模型强调模型的 #生物可解释性 （biological plausibility），但后期更关注于对某种特定认知能力的模拟，比如物体识别、语言理解等。尤其在引入误差反向传播来改进其学习能力之后，神经网络也越来越多地应用在各种模式识别任务上。随着训练数据的增多以及（并行）计算能力的增强，神经网络在很多模式识别任务上已经取得了很大的突破，特别是语音、图像等感知信号的处理上，表现出了卓越的学习能力。

 参考[[人工神经网络发展历史]]

虽然我们可以比较容易地构造一个人工神经网络，但是如何让人工神经网络具有学习能力并不是一件容易的事情。早期的神经网络模型并不具备学习能力。首个可学习的人工神经网络是 #赫布网络 ，采用一种基于赫布规则的无监督学习方法。 #感知器 是最早的具有机器学习思想的神经网络，但其学习方法无法扩展到多层的神经网络上。直到1980年左右， #反向传播算法 才有效地解决了多层神经网络的学习问题，并成为最为流行的神经网络学习算法。

人工神经网络诞生之初并不是用来解决机器学习问题。由于人工神经网络可以看作是一个通用的函数逼近器，一个两层的神经网络可以逼近任意的函数，因此人工神经网络可以看作一个可学习的函数，并应用到机器学习中。理论上，只要有足够的训练数据和神经元数量，人工神经网络就可以学到很多复杂的函数。人工神经网络模型的塑造任何函数的能力大小可以称为 #网络容量 （Network Capacity），与可以被储存在网络中的信息的复杂度以及数量相关。

我们主要关注于采用误差反向传播来进行学习的神经网络，即作为一种机器学习模型的神经网络。从机器学习的角度来看，神经网络一般可以看作是一个非线性模型，其基本组成单位为具有非线性激活函数的神经元，通过大量神经元之间的连接，使得神经网络成为一种高度非线性的模型。神经元之间的连接权重就是需要学习的参数，可以通过梯度下降方法来进行学习。

神经网络具有很强的拟合能力，常见的连续非线性函数都可以用神经网络来近似。因为神经网络的强大能力，反而容易在训练集上 #过拟合 。
根据 #通用近似定理 ，对于具有线性输出层和至少一个使用“ #挤压 ”性质的 #激活函数 的隐藏层组成的 #前馈神经网络 ，只要其隐藏层神经元的数量足够，它可以以任意的精度来近似任何从一个定义在实数空间 $\mathbb{R}^{d}$ 中的有界闭集函数 [Funahashi and Nakamura, 1993, Hornik et al., 1989]。所谓“挤压”性质的函数是指像 #Sigmoid 函数的有界函数，但神经网络的通用近似性质也被证明对于其它类型的激活函数，比如 #ReLU ，也都是适用的。
通用近似定理只是说明了神经网络的计算能力可以去近似一个给定的连续函数，但并没有给出如何找到这样一个网络，以及是否是最优的。此外，当应用到机器学习时，真实的映射函数并不知道，一般是通过 #经验风险最小化 和 #正则化 来进行 参数学习。
参考 [[神经网络的应用]] 和  [[神经网络的参数学习]]

一种典型的人工神经网络就是[[前馈神经网络]]。
[[卷积神经网络]]（ #CNN ）是一种具有局部连接、权重共享等特性的深层前馈神经网络。
[[循环神经网络]]（ #RNN ）是一类具有短期记忆能力的神经网络。
[[自编码器]] （ #Auto-Encoder ）是通过无监督的方式来学习一组数据的有效编码或表示。
