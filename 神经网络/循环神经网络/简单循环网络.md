#简单循环网络 （Simple Recurrent Network， #SRN ）[Elman, 1990]是一个非常简单的 #循环神经网络 ，只有一个隐藏层的神经网络。

在一个两层的 #前馈神经网络 中，连接存在相邻的层与层之间，隐藏层的节点之间是无连接的。而简单循环网络增加了从隐藏层到隐层的反馈连接。

假设在时刻t时，网络的输入为$x_t$，隐藏层状态（即隐藏层神经元活性值）为$h_t$不仅和当前时刻的输入$x_t$相关，也和上一个时刻的隐藏层状态$h_{t−1}$相关。$$\begin{aligned}
\mathbf{z}_{t} &=U \mathbf{h}_{t-1}+W \mathbf{x}_{t}+\mathbf{b}, \\
\mathbf{h}_{t} &=f\left(\mathbf{z}_{t}\right),
\end{aligned}$$其中$z_t$为隐藏层的净输入，$f(·)$是非线性激活函数，通常为logistic函数或tanh函数，$U$ 为状态-状态权重矩阵，$W$ 为状态-输入权重矩阵,$b$为偏置。$h_t$也经常直接写为$$h_t = f(Uh_{t−1} + Wx_t + b.)$$如果我们把每个时刻的状态都看作是前馈神经网络的一层的话，循环神经网络可以看作是在时间维度上权值共享的神经网络。
图给出了按时间展开的循环神经网络
![[按时间展开的循环神经网络.png]]

我们先定义一个完全连接的循环神经网络, 其输入为  $\mathbf{x}_{t}$ , 输出为  $\mathbf{y}_{t}$ ,$$\begin{aligned}
\mathbf{h}_{t} &=f\left(U \mathbf{h}_{t-1}+W \mathbf{x}_{t}+\mathbf{b}\right), \\
\mathbf{y}_{t} &=V \mathbf{h}_{t}
\end{aligned}$$
其中  $\mathbf{h}$  为隐状态,  $f(\cdot)$  为非线性激活函数,  $U$ 、 $W$ 、 $\mathbf{b}$  和  $V$  为网络参数。





