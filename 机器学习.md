# 概述
机器学习是 #人工智能 的一个重要分支，并逐渐成为推动人工智能发展的关键因素。作为一门学科， #机器学习(Machine Learning， #ML )通常指一类问题以及解决这类问题的方法，即如何从观测数据(样本)中寻找规律，并利用学习到的规律(模型)对未知或无法观测的数据进行预测。机器学习本质上属于 #应用统计学 ，但更多地关注于如何用计算机统计地估计复杂函数，而不太关注为这些函数提供置信区间。而[[深度学习]]问题是一个机器学习问题．

传统的机器学习主要关注于如何学习一个预测模型。一般需要首先将数据表示为一组 #特征 (Feature)，特征的表示形式可以是连续的数值、离散的符号或其它形式。然后将这些特征输入到预测模型，并输出预测结果。这类机器学习可以看作是 #浅层学习 (Shallow Learning)。浅层学习的一个重要特点是不涉及 #特征学习 ，其特征主要靠人工经验或特征转换方法来抽取。

目前机器学习中最主流的一类方法是统计学习方法，将机器学习问题看作统计推断问题，并且又可以进一步分为 #频率学派 和 #贝叶斯学派 ．频率学派将模型参数 𝜃 看作固定常数；而贝叶斯学派将参数 𝜃 看作随机变量，并且存在某种先验分布．

机器学习方法可以粗略地分为三个基本要素：[[模型]]、[[风险最小化准则|学习准则]]、[[优化算法]]．

为了衡量一个机器学习模型的好坏，需要给定一个测试集，用模型对测试集中的每一个样本进行预测，并根据预测结果计算[[评价指标|评价分数]]．

# 机器学习的一般步骤
当我们用机器学习来解决实际任务时，会面对多种多样的数据形式，比如声音、图像、文本等。像图像这类数据很自然地可以表示为一个连续的向量，比如图像直接将像素的颜色值(灰度值或RGB值)组成一个连续向量。而文本数据一般由离散符号组成。特别是计算机内部，每个符号都是表示为无意义的编码，很难找到合适的表示方式。因此，在实际任务中使用机器学习模型一般会包含以下几个步骤
![[传统机器学习的数据处理流程.png]]
- [[数据预处理]]：经过数据的预处理，如去除噪声等。比如在文本分类中，去除停用词等。
• #特征提取 ：从原始数据中提取一些有效的特征。比如在图像分类中，提取边缘、 #SIFT 特征等。
• #特征转换 ：对特征进行一定的加工，比如降维和升维。
• #预测 ：机器学习的核心部分，学习一个函数进行预测。
*很多特征转换方法也都是机器学习方法。*

上述流程中，每步特征处理以及预测一般都是分开进行处理的。传统的机器学习模型主要关注于最后一步，即构建预测函数。但是实际操作过程中，不同预测模型的性能相差不多，而前三步中的特征处理对最终系统的准确性有着十分关键的作用。由于特征处理一般都需要人工干预完成，利用人类的经验来选取好的特征，并最终提高机器学习系统的性能。因此，很多的机器学习问题变成了 [[特征工程]] (Feature Engineering)问题。开发一个机器学习系统的主要工作量都消耗在了预处理、特征提取以及特征转换上。

# 机器学习的算法类型
机器学习算法可以按照不同的标准来进行分类．比如按函数 𝑓(𝒙; 𝜃) 的不同，机器学习算法可以分为[[线性模型]]和[[非线性模型]]；按照学习准则的不同，机器学习算法也可以分为统计方法和非统计方法．但一般来说，我们会按照训练样本提供的信息以及反馈方式的不同，将机器学习算法分为以下几类：
## 监督学习
如果机器学习的目标是建模样本的特征 𝒙 和标签 𝑦 之间的关系：𝑦 = 𝑓(𝒙; 𝜃) 或 𝑝(𝑦|𝒙; 𝜃)，并且训练集中每个样本都有标签，那么这类机器学习称为 [[监督学习]] (Supervised Learning)．根据标签类型的不同，监督学习又可以分为 [[回归]]问题、[[分类]]问题和[[结构化学习]]问题．
## 无监督学习
[[无监督学习]]（Unsupervised Learning，UL）是指从不包含目标标签的训练样本中自动学习到一些有价值的信息．典型的无监督学习问题有[[聚类]]、[[概率密度估计|密度估计]]、[[特征学习]]、[[降维]]等．如果监督学习是建立输入-输出之间的映射关系，无监督学习就是发现隐藏的数据中的有价值信息，包括有效的特征、类别、结构以及概率分布等。 监督学习需要每个样本都有标签，而无监督学习则不需要标签。
## 强化学习
[[强化学习]]（Reinforcement Learning，RL）是一类通过交互来学习的机器学习算法．在强化学习中，智能体根据环境的状态做出一个动作，并得到即时或延时的奖励．智能体在和环境的交互中不断学习并调整策略，以取得最大化的期望总回报．
强化学习和监督学习的不同在于，强化学习不需要显式地以“输入/输出对”的方式给出训练样本，是一种在线的学习机制．
## 其他
一般而言，监督学习通常需要大量的有标签数据集，这些数据集一般都需要由人工进行标注，成本很高．因此，也出现了很多[[弱监督学习]]（Weakly Supervised Learning）和[[半监督学习]]（Semi-Supervised Learning，SSL）的方法，希望从大规模的无标注数据中充分挖掘有用的信息，降低对标注样本数量的要求．

广义上讲，监督学习也可以看作是一个类特殊的无监督学习，即估计 #条件概率 $p(y|x)$。条件概率$p(y|x)$可以通过 #贝叶斯公式 转为估计概率$p(y)$和$p(x|y)$，并通过 #无监督密度估计 来求解。
$$\begin{array}{llll} 
\hline 
& \text { 监督学习 } & \text { 无监督学习 } & \text { 强化学习 } \\
\hline 
\text { 训练样本 } &
\text { 训练集 } \left\{\left(\boldsymbol{x}^{(n)}, y^{(n)}\right)\right\}_{n=1}^{N} &
\text { 训练集 } \left\{\boldsymbol{x}^{n}\right\}_{n=1}^{N} &
\text { 智能体和环境交互的轨迹 } \tau \text { 和累积奖励 } G_{\tau}  \\
& & & \\
\text { 优化目标 } & 
y=f(\boldsymbol{x}) \text { 或 } p(y \mid \boldsymbol{x}) &
p(\boldsymbol{x}) \text { 或带隐变量 } \boldsymbol{z} \text { 的 } p(\boldsymbol{x} \mid \boldsymbol{z})&
\text { 期望总回报 } \mathbb{E}_{\tau}\left[G_{\tau}\right] \\
& & & \\
\text { 学习准则 } &
\text { 期望风险最小化、最大似然估计 } & \text { 最大似然估计、最小重构错误 } & \text { 策略评估、策略改进 } \\
\hline 
\end{array}$$


# 机器学习的理论基础
当使用机器学习方法来解决某个特定问题时，通常靠经验或者多次试验来选择合适的模型、训练样本数量以及学习算法收敛的速度等．但是经验判断或多次试验往往成本比较高，也不太可靠，因此希望有一套理论能够分析问题难度、计算模型能力，为学习算法提供理论保证，并指导机器学习模型和学习算法的设计．这就是计算学习理论． #计算学习理论 （Computational Learning Theory）是机器学习的理论基础，其中最基础的理论就是[[PAC学习理论|可能近似正确]]（Probably Approximately Correct，PAC）学习理论．


# 其他
### 模式识别
机器学习问题在早期的工程领域也经常称为 #模式识别 （Pattern Recognition，PR），但模式识别更偏向于具体的应用任务，比如光学字符识别、语音识别，人脸识别等。以 #手写数字识别 为例，这些任务的特点是对于我们人类而言，这些任务很容易完成，但我们不知道自己是如何做到的，因此也很难人工设计一个计算机程序来解决这些任务。一个可行的方法是设计一个算法可以让计算机自己从有标注的样本上学习其中的规律，并用来完成各种识别任务。随着机器学习技术的应用越来越广，现在机器学习的概念逐渐替代模式识别，成为这一类问题及其解决方法的统称。

### 机器学习流派（统计学习方法流派）
#频率学派 ：模型的参数是未知但客观存在的固定值.参数求解通过优化似然函数等.
#贝叶斯学派 ：模型的参数是本身有分布的未观察到的随机变量. 参数求解通过：
	1. 假定参数服从先验分布;
	2. 基于观测数据计算参数的后验分布.
最简单的例子即，回归模型与感知机的区别：
对于同样结构的模型,估计模型参数方法不同：回归模型通过最大似然估计求解,而感知机通过梯度下降.

