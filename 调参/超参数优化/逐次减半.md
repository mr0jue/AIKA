将超参数优化看作一种非随机的[[最优臂问题]]．假设要尝试 𝑁 组超参数配置，总共可利用的资源预算（摇臂的次数）为𝐵，我们可以通过`𝑇 = ⌈log_2(𝑁)⌉ − 1`轮逐次减半的方法来选取最优的配置，

```
输入: 预算𝐵，𝑁 个超参数配置{𝒙_𝑛}{𝑛=1,...,𝑁}
1 𝑇 ← ⌈log_2(𝑁)⌉ − 1; 
2 随机初始化𝒮0 = {𝒙_𝑛}{𝑛=1,...,𝑁}; 
3 for 𝑡 ← 1 to 𝑇 do
4 	𝑟_𝑡 ← ⌊ 𝐵/(|𝒮𝑡|×𝑇) ⌋; 
5 	给𝑆𝑡 中的每组配置分配𝑟𝑡 的资源; 
6 	运行𝑆𝑡 所有配置，评估结果为𝒚𝑡; 
7 	根据评估结果，选取 |𝑆𝑡|/2 组最优的配置 𝒮𝑡 ← arg max(𝒮𝑡, 𝒚𝑡, |𝒮𝑡|/2) ;
	// arg max(𝒮, 𝒚, 𝑚)为从集合𝒮 中选取𝑚个元素，对应最优的𝑚个评估结果． 
8 end
输出: 最优配置𝒮𝐾
```
在逐次减半方法中，尝试的超参数配置数量𝑁 十分关键．如果𝑁 越大，得到最佳配置的机会也越大，但每组配置分到的资源就越少，这样早期的评估结果可能不准确．反之，如果 𝑁 越小，每组超参数配置的评估会越准确，但有可能无法得到最优的配置．因此，如何设置 𝑁 是平衡“利用-探索”的一个关键因素．一种改进的方法是HyperBand方法[Li et al., 2017b]，通过尝试不同的𝑁 来选取最优参数．