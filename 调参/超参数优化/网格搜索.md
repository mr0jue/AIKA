网格搜索（Grid Search）是一种通过尝试所有超参数的组合来寻址合适一组超参数配置的方法．假设总共有𝐾 个超参数，第𝑘个超参数的可以取𝑚𝑘 个值．那么总共的配置组合数量为 `𝑚1 × 𝑚2 × ⋯ × 𝑚𝐾`．如果超参数是连续的，可以将超参数离散化，选择几个“经验”值．比如学习率𝛼，我们可以设置
𝛼 ∈ {0.01, 0.1, 0.5, 1.0}.
一般而言，对于连续的超参数，我们不能按等间隔的方式进行离散化，需要根据超参数自身的特点进行离散化．网格搜索根据这些超参数的不同组合分别训练一个模型，然后测试这些模型在开发集上的性能，选取一组性能最好的配置． 

手动的给出一个模型中你想要改动的所用的参数,将待搜索的参数在一定的空间范围内划分成网格,程序自动的帮你使用穷举法来将所用的参数都运行一遍,通过网格中的所有的点结合交叉验证等评分方法来寻找最优化参数.
例如在\[0,0.2]范围内以0.05为步长，则实际要评估的候选参数值有5个，最终是从这5个候选值中产生选定值.
例如假定算法有3个参数，每个参数仅考虑5个候选值，这样对每一组训练/测试集就有5^3=125个模型需考察

# 随机搜索
不同超参数对模型性能的影响有很大差异． 有些超参数（比如[[正则化]]系数）对模型性能的影响有限， 而另一些超参数（比如[[学习率]]）对模型性能影响比较大． 在这种情况下， 采用网格搜索会在不重要的超参数上进行不必要的尝试． 
一种在实践中比较有效的改进方法是对超参数进行随机组合， 然后选取一个性能最好的配置，这就是随机搜索（Random Search）[Bergstra et al., 2012]． 随机搜索在实践中更容易实现，一般会比网格搜索更加有效．
网格搜索和随机搜索都没有利用不同超参数组合之间的相关性， 即如果模型的超参数组合比较类似，其模型性能也是比较接近的． 因此这两种搜索方式一般都比较低效． 