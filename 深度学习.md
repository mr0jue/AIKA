# 概述
**深度学习是机器学习的一个子问题**．
深度学习（Deep Learning，DL）通过构建具有一定“深度”的模型，并通过学习算法来让模型自动从数据中自动学习到有效的特征表示．*所谓“深度”是指原始数据进行非线性特征转换的次数．*经过多层的特征转换，深度学习模型把原始数据变成更高层次、更抽象的表示．从而避免特征工程，以替代人工设计的特征，从而最终提升预测模型的准确率．
目前，深度学习采用的模型主要是[[神经网络]]模型，其主要原因是神经网络模型可以使用误差反向传播算法，从而可以比较好地解决贡献度分配问题．只要是超过一层的神经网络都会存在贡献度分配问题，因此可以将超过一层的神经网络都看作深度学习模型．随着深度学习的快速发展，模型深度也从早期的5 ∼ 10层增加到目前的数百层．随着模型深度的不断增加，其特征表示的能力也越来越强，从而使后续的预测更加容易．

网络优化的改善方法
# 深度学习的难点问题和改善方法
## [[最优化问题]]
网络优化是指寻找一个神经网络模型来使得经验（或结构）风险最小化的过程， 包括模型选择以及参数学习等． 
深度神经网络的优化十分困难． 是一个具有挑战性的问题． 
首先，深度神经网络是一个高度非线性的模型，其风险函数是一个非凸函数， 因此风险最小化是一个非凸优化问题． 神经网络的损失函数是一个非凸函数，找到全局最优解通常比较困难． 
其次， 深度神经网络的参数通常非常多， 训练数据也比较大， 因此也无法使用计算代价很高的二阶优化方法，而一阶优化方法的训练效率通常比较低． 
此外，深度神经网络存在梯度消失或爆炸问题，导致基于梯度的优化方法经常失效．
### 问题
网络结构多样性
## 过拟合问题
机器学习模型的关键是泛化问题，即在样本真实分布上的期望风险最小化．而训练数据集上的经验风险最小化和期望风险并不一致． 
由于深度神经网络的复杂度比较高，并且拟合能力很强，很容易在训练集上产生过拟合． 因此在训练深度神经网络时，如何提高神经网络的泛化能力反而成为影响模型能力的最关键因素．需要通过一定的正则化方法来改进网络的泛化能力．

 网络正则化方法
正则化（Regularization）是一类通过限制模型复杂度，从而避免过拟合，提高泛化能力的方法，比如引入约束、增加先验、提前停止等．
在传统的机器学习中， 提高泛化能力的方法主要是限制模型复杂度， 比如采用 ℓ1 和 ℓ2 正则化等方式． 而在训练深度神经网络时， 特别是在[[过度参数化]]（Over-Parameterization）时，ℓ1 和 ℓ2 正则化的效果往往不如浅层机器学习模型中显著．因此训练深度学习模型时， 往往还会使用其他的正则化方法， 比如数据增强、提前停止、丢弃法、集成法等．